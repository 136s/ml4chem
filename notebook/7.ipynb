{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from rdkit import Chem\n",
    "from torch import nn, tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.distributions import OneHotCategorical\n",
    "from tqdm import tqdm\n",
    "from smiles_vocab import SmilesVocabulary\n",
    "from torchdrug.data.molecule import PackedMolecule\n",
    "from torchdrug.metrics import penalized_logP\n",
    "\n",
    "from rdkit import RDLogger\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "\n",
    "def filter_valid(smiles_list):\n",
    "    success_list = []\n",
    "    fail_idx_list = []\n",
    "    for each_idx, each_smiles in enumerate(smiles_list):\n",
    "        try:\n",
    "            smiles = Chem.MolToSmiles(Chem.MolFromSmiles(each_smiles))\n",
    "            success_list.append(smiles)\n",
    "        except:\n",
    "            fail_idx_list.append(each_idx)\n",
    "    return success_list, fail_idx_list\n",
    "\n",
    "\n",
    "class SmilesLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab, hidden_size, n_layers):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        vocab_size = len(self.vocab.char_list)\n",
    "        self.lstm = nn.LSTM(vocab_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.out_linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.out_activation = nn.Softmax(2)\n",
    "        self.out_dist_cls = OneHotCategorical\n",
    "        self.loss_func = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, in_seq):\n",
    "        in_seq_one_hot = nn.functional.one_hot(\n",
    "            in_seq, num_classes=self.lstm.input_size\n",
    "        ).to(torch.float)\n",
    "        out, _ = self.lstm(in_seq_one_hot)\n",
    "        return self.out_linear(out)\n",
    "\n",
    "    def loss(self, in_seq, out_seq):\n",
    "        return self.loss_func(self.forward(in_seq).transpose(1, 2), out_seq)\n",
    "\n",
    "    def generate(self, sample_size=1, max_len=100, smiles=True):\n",
    "        device = next(self.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            self.eval()\n",
    "            in_seq_one_hot = (\n",
    "                nn.functional.one_hot(\n",
    "                    tensor([[self.vocab.sos_idx]] * sample_size),\n",
    "                    num_classes=self.lstm.input_size,\n",
    "                )\n",
    "                .to(torch.float)\n",
    "                .to(device)\n",
    "            )\n",
    "            h = torch.zeros(\n",
    "                self.lstm.num_layers, sample_size, self.lstm.hidden_size\n",
    "            ).to(device)\n",
    "            c = torch.zeros(\n",
    "                self.lstm.num_layers, sample_size, self.lstm.hidden_size\n",
    "            ).to(device)\n",
    "            out_seq_one_hot = in_seq_one_hot.clone()\n",
    "            out = in_seq_one_hot\n",
    "            for _ in range(max_len):\n",
    "                out, (h, c) = self.lstm(out, (h, c))\n",
    "                out = self.out_activation(self.out_linear(out))\n",
    "                out = self.out_dist_cls(probs=out).sample()\n",
    "                out_seq_one_hot = torch.cat((out_seq_one_hot, out), dim=1)\n",
    "            self.train()\n",
    "            if smiles:\n",
    "                return [\n",
    "                    self.vocab.seq2smiles(each_onehot)\n",
    "                    for each_onehot in torch.argmax(out_seq_one_hot, dim=2)\n",
    "                ]\n",
    "            return out_seq_one_hot\n",
    "\n",
    "\n",
    "def trainer(\n",
    "    model,\n",
    "    train_tensor,\n",
    "    val_tensor,\n",
    "    smiles_vocab,\n",
    "    lr,\n",
    "    n_epoch,\n",
    "    batch_size,\n",
    "    print_freq,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_dataset = TensorDataset(train_tensor[:, :-1], train_tensor[:, 1:])\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataset = TensorDataset(val_tensor[:, :-1], val_tensor[:, 1:])\n",
    "    val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    running_loss = 0\n",
    "    running_sample_size = 0\n",
    "    batch_idx = 0\n",
    "    for each_epoch in range(n_epoch):\n",
    "        for each_train_batch in tqdm(train_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            each_loss = model.loss(\n",
    "                each_train_batch[0].to(device), each_train_batch[1].to(device)\n",
    "            )\n",
    "            each_loss = each_loss.mean()\n",
    "            running_loss += each_loss.item()\n",
    "            running_sample_size += len(each_train_batch[0])\n",
    "            each_loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx + 1) % print_freq == 0:\n",
    "                train_loss_list.append(\n",
    "                    (batch_idx + 1, running_loss / running_sample_size)\n",
    "                )\n",
    "                print(\n",
    "                    \"#update: {},\\tper-example \"\n",
    "                    \"train loss:\\t{}\".format(\n",
    "                        batch_idx + 1, running_loss / running_sample_size\n",
    "                    )\n",
    "                )\n",
    "                running_loss = 0\n",
    "                running_sample_size = 0\n",
    "                if (batch_idx + 1) % (print_freq * 10) == 0:\n",
    "                    val_loss = 0\n",
    "                    with torch.no_grad():\n",
    "                        for each_val_batch in val_data_loader:\n",
    "                            each_val_loss = model.loss(\n",
    "                                each_val_batch[0].to(device),\n",
    "                                each_val_batch[1].to(device),\n",
    "                            )\n",
    "                            each_val_loss = each_val_loss.mean()\n",
    "                            val_loss += each_val_loss.item()\n",
    "                    val_loss_list.append((batch_idx + 1, val_loss / len(val_dataset)))\n",
    "                    print(\n",
    "                        \"#update: {},\\tper-example \"\n",
    "                        \"val loss:\\t{}\".format(\n",
    "                            batch_idx + 1, val_loss / len(val_dataset)\n",
    "                        )\n",
    "                    )\n",
    "            batch_idx += 1\n",
    "    return model, train_loss_list, val_loss_list\n",
    "\n",
    "\n",
    "def rl_trainer(\n",
    "    model,\n",
    "    train_tensor,\n",
    "    train_tgt,\n",
    "    smiles_vocab,\n",
    "    n_epoch=1000,\n",
    "    sample_size=1000,\n",
    "    batch_size=128,\n",
    "    print_freq=100,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    train_loss_list = []\n",
    "    avg_reward_list = []\n",
    "    running_loss = 0\n",
    "    running_sample_size = 0\n",
    "    batch_idx = 0\n",
    "    for each_epoch in range(n_epoch):\n",
    "        rl_tensor = model.generate(sample_size=sample_size, smiles=False)\n",
    "        rl_tensor = torch.argmax(rl_tensor, dim=2)\n",
    "        rl_smiles_list, fail_idx_list = filter_valid(\n",
    "            [model.vocab.seq2smiles(each_idx_seq) for each_idx_seq in rl_tensor]\n",
    "        )\n",
    "        if not rl_smiles_list:\n",
    "            rl_smiles_list = train_tensor[:sample_size]\n",
    "            plogp_tensor = train_tgt[:sample_size]\n",
    "        else:\n",
    "            rl_packed_dataset = PackedMolecule.from_smiles(rl_smiles_list)\n",
    "            _plogp_tensor = penalized_logP(rl_packed_dataset)\n",
    "            plogp_tensor = torch.zeros(len(rl_tensor), dtype=torch.float)\n",
    "            each_other_idx = 0\n",
    "            for each_idx in range(len(plogp_tensor)):\n",
    "                if each_idx in fail_idx_list:\n",
    "                    plogp_tensor[each_idx] = -30.0\n",
    "                else:\n",
    "                    plogp_tensor[each_idx] = _plogp_tensor[each_other_idx]\n",
    "                    each_other_idx += 1\n",
    "            print(\" * mean plogp: {}\".format(plogp_tensor.mean()))\n",
    "            avg_reward_list.append((each_epoch, plogp_tensor.mean().item()))\n",
    "        rl_dataset = TensorDataset(rl_tensor[:, :-1], rl_tensor[:, 1:], plogp_tensor)\n",
    "        rl_data_loader = DataLoader(rl_dataset, batch_size=batch_size, shuffle=True)\n",
    "        for each_train_batch in tqdm(rl_data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            each_reward = each_train_batch[2].to(device)\n",
    "            each_loss = model.loss(\n",
    "                each_train_batch[0].to(device), each_train_batch[1].to(device)\n",
    "            )\n",
    "            each_loss = (each_reward @ each_loss).mean() / len(each_reward)\n",
    "            running_loss += each_loss.item()\n",
    "            running_sample_size += len(each_train_batch[0])\n",
    "            each_loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx + 1) % print_freq == 0:\n",
    "                train_loss_list.append(\n",
    "                    (batch_idx + 1, running_loss / running_sample_size)\n",
    "                )\n",
    "                print(\n",
    "                    \"#update: {},\\tper-example \"\n",
    "                    \"train loss:\\t{}\".format(\n",
    "                        batch_idx + 1, running_loss / running_sample_size\n",
    "                    )\n",
    "                )\n",
    "                running_loss = 0\n",
    "                running_sample_size = 0\n",
    "            batch_idx += 1\n",
    "    return model, train_loss_list, avg_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from smiles_vocab import SmilesVocabulary\n",
    "# from smiles_lstm_reinforce import SmilesLSTM, trainer, rl_trainer\n",
    "from metrics import plogp\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from torchdrug.data.molecule import PackedMolecule\n",
    "from torchdrug.metrics import penalized_logP\n",
    "from tqdm import tqdm\n",
    "from rdkit import RDLogger\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "RDLogger.DisableLog(\"*\")\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "def valid_ratio(smiles_list):\n",
    "    n_success = 0\n",
    "    success_list = []\n",
    "    for each_smiles in smiles_list:\n",
    "        try:\n",
    "            smiles = Chem.MolToSmiles(Chem.MolFromSmiles(each_smiles))\n",
    "            n_success += 1\n",
    "            success_list.append(smiles)\n",
    "        except:\n",
    "            pass\n",
    "    return n_success / len(smiles_list), success_list\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    smiles_vocab = SmilesVocabulary()\n",
    "    train_tensor, train_smiles_list = smiles_vocab.batch_update_from_file(\n",
    "        \"train.smi\", return_smiles=True\n",
    "    )\n",
    "    val_tensor, val_smiles_list = smiles_vocab.batch_update_from_file(\n",
    "        \"val.smi\", return_smiles=True\n",
    "    )\n",
    "\n",
    "    train_plogp_tensor = plogp(train_smiles_list, \"train_plogp.pklz\")\n",
    "    val_plogp_tensor = plogp(val_smiles_list, \"val_plogp.pklz\")\n",
    "\n",
    "    lstm = SmilesLSTM(smiles_vocab, hidden_size=512, n_layers=4)\n",
    "\n",
    "    try:\n",
    "        lstm.load_state_dict(torch.load(\"pretrained.pt\"))\n",
    "        print(\"load pretrained.pt\")\n",
    "    except:\n",
    "        lstm, train_loss_list, val_loss_list = trainer(\n",
    "            lstm,\n",
    "            train_tensor,\n",
    "            val_tensor,\n",
    "            smiles_vocab,\n",
    "            lr=1e-3,\n",
    "            n_epoch=20,\n",
    "            batch_size=128,\n",
    "            print_freq=100,\n",
    "            device=device,\n",
    "        )\n",
    "        torch.save(lstm.state_dict(), \"pretrained.pt\")\n",
    "        plt.plot(*list(zip(*train_loss_list)), label=\"train loss\")\n",
    "        plt.plot(*list(zip(*val_loss_list)), label=\"validation loss\", marker=\"*\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"# of updates\")\n",
    "        plt.ylabel(\"Loss function\")\n",
    "        plt.savefig(\"learning_curve.pdf\")\n",
    "        plt.clf()\n",
    "\n",
    "    lstm, rl_train_loss_list, avg_reward_list = rl_trainer(\n",
    "        lstm,\n",
    "        train_tensor,\n",
    "        train_plogp_tensor,\n",
    "        smiles_vocab,\n",
    "        n_epoch=1000,\n",
    "        sample_size=128,\n",
    "        batch_size=128,\n",
    "        print_freq=100,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    plt.plot(*list(zip(*avg_reward_list)), marker=\".\")\n",
    "    plt.xlabel(\"# of updates\")\n",
    "    plt.ylabel(\"Expected return\")\n",
    "    plt.savefig(\"rl_curve.pdf\")\n",
    "\n",
    "    smiles_list = lstm.generate(sample_size=1000)\n",
    "    success_ratio, success_smiles_list = valid_ratio(smiles_list)\n",
    "    print(\"success rate: {}\".format(success_ratio))\n",
    "\n",
    "    if success_smiles_list:\n",
    "        success_packed_dataset = PackedMolecule.from_smiles(success_smiles_list)\n",
    "        plogp_tensor = penalized_logP(success_packed_dataset)\n",
    "        print(\" * plogp mean = {}\".format(plogp_tensor.mean()))\n",
    "        res_df = pd.DataFrame(\n",
    "            zip(smiles_list, plogp_tensor.tolist()), columns=[\"smiles\", \"plogp\"]\n",
    "        )\n",
    "        with gzip.open(\"mol.pklz\", \"wb\") as f:\n",
    "            pickle.dump(res_df, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
