{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/rusty1s/pytorch_scatter.git\n",
    "! pip install git+https://github.com/rusty1s/pytorch_cluster.git\n",
    "! conda install -c conda-forge ninja lmdb fair-esm\n",
    "! pip install git+https://github.com/136s/torchdrug.git\n",
    "\n",
    "! conda install -c conda-forge botorch gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P.205 リスト6.1: 4,5,6,7/metrics.py\n",
    "\n",
    "import gzip\n",
    "import math\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "import torch\n",
    "from torchdrug.data.molecule import PackedMolecule\n",
    "from torchdrug.metrics import penalized_logP\n",
    "\n",
    "\n",
    "def filter_valid(smiles_list):\n",
    "    success_list = []\n",
    "    fail_idx_list = []\n",
    "    for each_idx, each_smiles in enumerate(smiles_list):\n",
    "        try:\n",
    "            smiles = Chem.MolToSmiles(Chem.MolFromSmiles(each_smiles))\n",
    "            success_list.append(smiles)\n",
    "        except:\n",
    "            fail_idx_list.append(each_idx)\n",
    "    return success_list, fail_idx_list\n",
    "\n",
    "\n",
    "def compute_plogp(smiles_list):\n",
    "    filtered_smiles_list, fail_idx_list = filter_valid(smiles_list)\n",
    "    if not filtered_smiles_list:\n",
    "        return -30.0 * torch.ones(len(smiles_list))\n",
    "    packed_dataset = PackedMolecule.from_smiles(filtered_smiles_list)\n",
    "    _plogp_tensor = penalized_logP(packed_dataset)\n",
    "    plogp_tensor = torch.zeros(len(smiles_list), dtype=torch.float)\n",
    "    each_other_idx = 0\n",
    "    for each_idx in range(len(plogp_tensor)):\n",
    "        if each_idx in fail_idx_list:\n",
    "            plogp_tensor[each_idx] = -30.0\n",
    "        else:\n",
    "            plogp_tensor[each_idx] = _plogp_tensor[each_other_idx]\n",
    "            each_other_idx += 1\n",
    "    return plogp_tensor\n",
    "\n",
    "\n",
    "def plogp(smiles_list, file_name=\"plogp.pklz\", batch_size=1024):\n",
    "    n_iter = math.ceil(len(smiles_list) / batch_size)\n",
    "\n",
    "    try:\n",
    "        with gzip.open(file_name, \"rb\") as f:\n",
    "            plogp_tensor = pickle.load(f)\n",
    "        if len(plogp_tensor) != len(smiles_list):\n",
    "            raise RuntimeError\n",
    "    except:\n",
    "        plogp_tensor_list = []\n",
    "        for each_batch_idx in tqdm(range(n_iter)):\n",
    "            packed_dataset = PackedMolecule.from_smiles(\n",
    "                smiles_list[\n",
    "                    each_batch_idx\n",
    "                    * batch_size : min(\n",
    "                        (each_batch_idx + 1) * batch_size, len(smiles_list)\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            plogp_tensor_list.append(penalized_logP(packed_dataset))\n",
    "        plogp_tensor = torch.cat(plogp_tensor_list)\n",
    "\n",
    "        with gzip.open(file_name, \"wb\") as f:\n",
    "            pickle.dump(plogp_tensor, f)\n",
    "    return plogp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P.207 リスト6.2: 4,5,6,7/smiles_vae_bo_main.py\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.utils.transforms import standardize, normalize, unnormalize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from smiles_vocab import SmilesVocabulary\n",
    "from smiles_vae import SmilesVAE\n",
    "\n",
    "# from metrics import filter_valid, compute_plogp\n",
    "\n",
    "from rdkit import RDLogger\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "\n",
    "def bo_dataset_construction(\n",
    "    vae, input_tensor, smiles_list, batch_size=128, max_batch=10\n",
    "):\n",
    "    dataloader = DataLoader(\n",
    "        TensorDataset(input_tensor), batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    z_list = []\n",
    "    plogp_list = []\n",
    "    out_smiles_list = []\n",
    "    for each_batch_idx, each_tensor in enumerate(dataloader):\n",
    "        if each_batch_idx == max_batch:\n",
    "            break\n",
    "        smiles_sublist = smiles_list[\n",
    "            batch_size * each_batch_idx : batch_size * (each_batch_idx + 1)\n",
    "        ]\n",
    "        with torch.no_grad():\n",
    "            z, _ = vae.encode(each_tensor[0].to(vae.device))\n",
    "        z_list.append(z.to(\"cpu\").double())\n",
    "        plogp_tensor = compute_plogp(smiles_sublist)\n",
    "        plogp_list.append(plogp_tensor.double())\n",
    "        out_smiles_list.extend(smiles_sublist)\n",
    "    return (torch.cat(z_list), torch.cat(plogp_list), out_smiles_list)\n",
    "\n",
    "\n",
    "def obj_func(z, vae):\n",
    "    z = z.to(torch.float32)\n",
    "    for _ in range(100):\n",
    "        smiles_list = vae.generate(z, deterministic=False)\n",
    "        success_list, failed_idx_list = filter_valid(smiles_list)\n",
    "        if success_list:\n",
    "            smiles_list = success_list[:1]\n",
    "            break\n",
    "    plogp_tensor = compute_plogp(smiles_list).double()\n",
    "    return plogp_tensor, smiles_list\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    smiles_vocab = SmilesVocabulary()\n",
    "    train_tensor, train_smiles_list = smiles_vocab.batch_update_from_file(\n",
    "        \"train.smi\", with_smiles=True\n",
    "    )\n",
    "    val_tensor, val_smiles_list = smiles_vocab.batch_update_from_file(\n",
    "        \"val.smi\", with_smiles=True\n",
    "    )\n",
    "    max_len = train_tensor.shape[1]\n",
    "    latent_dim = 64\n",
    "\n",
    "    vae = SmilesVAE(\n",
    "        smiles_vocab,\n",
    "        latent_dim=latent_dim,\n",
    "        emb_dim=256,\n",
    "        encoder_params={\n",
    "            \"hidden_size\": 512,\n",
    "            \"num_layers\": 1,\n",
    "            \"bidirectional\": False,\n",
    "            \"dropout\": 0.0,\n",
    "        },\n",
    "        decoder_params={\"hidden_size\": 512, \"num_layers\": 1, \"dropout\": 0.0},\n",
    "        encoder2out_params={\"out_dim_list\": [256]},\n",
    "        max_len=max_len,\n",
    "    ).to(torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\")\n",
    "    vae.load_state_dict(torch.load(\"vae.pt\"))\n",
    "    vae.eval()\n",
    "\n",
    "    z_tensor, plogp_tensor, smiles_list = bo_dataset_construction(\n",
    "        vae, train_tensor, train_smiles_list\n",
    "    )\n",
    "    n_trial = 500\n",
    "\n",
    "    for each_trial in range(n_trial):\n",
    "        standardized_y = standardize(plogp_tensor).reshape(-1, 1)\n",
    "        bounds = torch.stack([z_tensor.min(dim=0)[0], z_tensor.max(dim=0)[0]])\n",
    "        normalized_X = normalize(z_tensor, bounds)\n",
    "        gp = SingleTaskGP(normalized_X, standardized_y)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_mll(mll)\n",
    "        UCB = UpperConfidenceBound(gp, beta=0.1)\n",
    "        candidate, acq_value = optimize_acqf(\n",
    "            UCB,\n",
    "            bounds=torch.stack([torch.zeros(latent_dim), torch.ones(latent_dim)]),\n",
    "            q=1,\n",
    "            num_restarts=5,\n",
    "            raw_samples=10,\n",
    "        )\n",
    "        unnormalized_candidate = unnormalize(candidate, bounds)\n",
    "\n",
    "        plogp_val, each_smiles_list = obj_func(unnormalized_candidate, vae)\n",
    "        z_tensor = torch.cat([z_tensor, unnormalized_candidate])\n",
    "        plogp_tensor = torch.cat([plogp_tensor, plogp_val])\n",
    "        smiles_list.extend(each_smiles_list)\n",
    "        print(\" * {}\\t{}\".format(each_trial, plogp_val))\n",
    "\n",
    "    plogp_tensor = plogp_tensor[-n_trial:]\n",
    "    smiles_list = smiles_list[-n_trial:]\n",
    "    _, ascending_idx_tensor = plogp_tensor.sort()\n",
    "\n",
    "    print(\"plogp\\tsmiles\")\n",
    "    out_dict_list = []\n",
    "    for each_idx in ascending_idx_tensor.tolist()[::-1][:10]:\n",
    "        print(\"{}\\t{}\".format(plogp_tensor[each_idx], smiles_list[each_idx]))\n",
    "        out_dict_list.append(\n",
    "            {\"smiles\": smiles_list[each_idx], \"plogp\": plogp_tensor[each_idx]}\n",
    "        )\n",
    "\n",
    "    res_df = pd.DataFrame(out_dict_list)\n",
    "    with gzip.open(\"smiles_vae_best_mol.pklz\", \"wb\") as f:\n",
    "        pickle.dump(res_df, f)\n",
    "\n",
    "    with gzip.open(\"smiles_vae_bo_full.pklz\", \"wb\") as f:\n",
    "        pickle.dump((smiles_list, plogp_tensor), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinvent4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
